---
layout: post
title: 相似性度量
description: 
category: blog
---

##1 Pearson相关系数
 
Pearson是一个介于-1和1之间的值，用来描述两组**线性数据一同变化移动的趋势**。

当两个变量的线性关系增强时，相关系数趋于1或-1；当一个变量增大，另一个变量也增大时，表明它们之间是正相关的，相关系数大于0；如果一个变量增大，另一个变量却减小，表明它们之间是负相关的，相关系数小于0；如果相关系数等于0，表明它们之间不存在线性相关关系。

用数学公式表示，皮尔森相关系数等于两个变量的协方差除于两个变量的标准差。 

![Pearson 公式](http://mazhiyuan.github.io/images/cf-1.jpg)

R(u,i)指User u发生过行为的物品i，R(i)为平均值，可见Pearson考虑了物品的均值，可以认为在物品纬度做了归一，这一点与**调整余弦公式**有所不同。

由于Pearson相关系数描述的是两组数据变化移动的趋势，所以在**基于User-Based的协同过滤系统中**，经常用于描述用户购买或评分变化的趋势，若趋势相近则Pearson系数趋近于1，也就是我们认为相似的用户。

**Pearson的缺陷**

以下图的数据作为测试用例 

![](http://mazhiyuan.github.io/images/cf-2.jpg)

*table 1 行表示用户（1～5）对项目（101～103）的一些评分值。*

- 未考虑重叠记录项的数量对相似度的影响

   直观来看，User1和User5用3个共同的评分项，并且给出的评分趋势相同，User1与User4只有2个相同评分项，虽然他们的趋势也相似，但是由于102的未知，可能是User2对102未发生行为，或者对102很讨厌，所以我们更希望User1和User5更相似，但结果是User1与User4有着更高的结果。**是因为pearson系数只会对共同评分的记录进行计算。**
   
   同样的场景在现实生活中也经常发生，比如两个用户共同观看了200部电影，虽然不一定给出相同或完全相近的评分，但只要他们之间的趋势相似也应该比另一位只观看了2部相同电影的相似度高！但事实并不如此，如果对这两部电影，两个用户给出的相似度相同或很相近，通过Pearson相关性计算出的相似度会明显大于观看了相同的200部电影的用户之间的相似度。 
   在Mahout中，通过设置可以解决这一问题。

- 如果只有一个重叠项则无法计算相关性

    从数学上讲，若只有一个重叠的记录，那么至少有一组记录的标准差为0，导致分母为0。从这一点也可以看出，**Pearson系数不适用于小的或者非常稀疏的数据集**。当然，这一特性也有它的好处，无法计算pearson系数可以认为这两组数据没有任何相关性。

- 如果一组记录的所有评分都一样则无法计算相关性

    理由同2
- Pearson系数对绝对数值不敏感

    考虑这三组数据：
    
    1:(1.0,2.0,3.0,4.0),
    
    2:(40.0,50.0,70.0,80.0),
    
    3:(50.0,60.0,70.0,80.0)
    
    我们可以直观的认为2和3更为相似，它们的重叠评分数目一致，趋势也相同，记录1虽然也满足上述的条件，但是它整体数值很低。在现实中，有人习惯于给出更高的评分，而有人则恰恰相反。
    利用Pearson计算它们之间的相似度为：
    
     1&2: 0.9899494936611665

     2&3: 0.9899494936611665

     1&3: 0.9999999999999999

   **故Pearson系数对绝对数值并不敏感，它只是描述了两组数据变化的趋势。**
 
##2 余弦相似度
余弦相似度用向量空间中两个向量**夹角的余弦值**作为衡量两个个体间差异的大小。

 ![cosine 公式](http://mazhiyuan.github.io/images/cf-3.jpg)

余弦相似度的计算方法是把用户的喜好作为n-维坐标系中的点，通过连接这些点与原点构成向量，两个用户之间的相似度值就是向量间夹角的余弦值。夹角越小代表两个用户越相似，夹角越大代表两个用户的相似度越小。在三角系数中，余弦值在[-1, 1]之间的，0度角的余弦值是1，180度角的余弦值是-1。

余弦相似度在计算时利用了向量相乘，一般当纬度不同时，以0值代替，这一点需要考虑。因为用户未对该物品发生行为，那么在计算时是否可以置为0，需要结合实际场景考虑。
##3 欧式距离
欧式距离是最简单的相似性度量方式了，它认为数据是n-维空间的点，通过计算点间真实距离判断是否相似，距离近的比距离远的更加相似。

![欧式公式](http://mazhiyuan.github.io/images/cf-4.jpg)

进过计算的结果是大于0的，但是往往为了方便比较将结果做了归一处理，得到一个小于1的值，值越大，相似性越大。

![变更公式](http://mazhiyuan.github.io/images/cf-5.jpg)

只要至少有一个共同评分项，就能用欧几里德距离计算相似度；如果没有共同评分项，那么欧几里德距离也就失去了作用，也意味着这两个用户或物品根本不相似。所以，欧式距离计算时只考虑共同记录。

**余弦相似度与欧式距离的异同**
余弦相似度与欧式距离都是将行为数据放置在n-维空间中，如下图
![异同](http://mazhiyuan.github.io/images/cf-6.jpg)

从图上可以看出欧式距离衡量的是空间各点间的绝对距离，跟各个点所在的位置直接相关；而余弦相似度衡量的是空间向量的夹角，体现在方向上的差异，而不是位置。如果拉伸A与B的长度，余弦相似度是保持不变的，因为夹角不变，而A、B两点的距离显然在发生改变，这就是欧氏距离和余弦相似度的不同之处。

根据欧氏距离和余弦相似度各自的计算方式和衡量特征，适用于不同的数据分析模型：欧氏距离能够体现个体数值特征的绝对差异，所以更多的用于需要从维度的数值大小中体现差异的分析；而余弦相似度更多的是从方向上区分差异，而对绝对的数值不敏感。

##4 余弦相似度的改进---调整余弦相似度
Pearson相似度和余弦相似度都不受绝对数值的影响，我们重新回顾Pearson相似度缺陷中第四点，用户的评分习惯问题。如果用余弦相似度去度量，这些用户的相似性可以得到和Pearson差不多的结论。问题就在于没有考虑用户评分时自身标准带来的影响，如果我们在计算时根据自身标准做归一处理，即可缓解这个问题，这就是调整余弦相似度

![acosin](http://mazhiyuan.github.io/images/cf-7.jpg)

这个公式中，每一个评分都减去了用户的评分均值后再参与计算。从公式角度看和Pearson系数的公式极其相似。但Pearson减去的是物品的评分均值，而调整余弦减去的是用户的评分均值。

这样在进行计算时，物品的评分就不受用户的个性所影响，所以调整余弦相似度在基于Item-Based的系统中往往表现的更好。
###5 Pearson的变形---Spearman相关性
Spearman相关性是Pearson系数的一个变形，它忽略了原始的偏好值，只是保留了原始值的**顺序**。它的结果只有-1和1，这两个值。Pearson有的缺点它都有，而且它更耗时，所以它往往用于学术研究，而不是实际项目。
##6 Jaccard系数
Jaccard系数和前面的5中相关度计算方式有很大的不同，它不关心用户对物品的具体评分值是多少，它只关心用户与物品之间是否存在关联关系。这一点可以用来解决Pearson相关系数缺点中的第1点。

![jaccard](http://mazhiyuan.github.io/images/cf-8.jpg)

更准确的说法为：**Jaccard系数主要用于计算符号度量或布尔值度量的个体间的相似度**，因为个体的特征属性都是由符号度量或者布尔值标识，因此无法衡量差异具体值的大小，只能获得“是否相同”这个结果，所以Jaccard系数只关心个体间共同具有的特征是否一致这个问题。Jaccard系数等于两个用户共同关联（不管喜欢还是不喜欢）的物品数量除于两个用户分别关联的所有物品数量。

![公式](http://mazhiyuan.github.io/images/cf-9.jpg)

其值介于[0, 1]之间，如果两个用户关联的物品完全相同，交集等于并集，值为1；如果没有任何关联，交集为空，值为0。

##7 log-likelihood系数--对数似然法
对数似然法是一个与Jaccard系数相似的方法。它评估的是重叠记录数目的不可能性。重叠记录越多，可能性越小，则越相似。对数似然比Jaccard系数效果好一点。它的值是一个小于1的数。
##8 如何处理缺失值
从上面的描述我们可以看到，除了Jaccard和log-likelihood不要求行为数据的具体值外，其他的方式都需要使用具体值，而且大多数相似性度量方式只对共同行为记录进行计算。那么在小的数据集或是稀疏度较高的数据集中，这些相似性方法都不会表现的太好。

这时我们利用一些方式推论出那些缺失值，这样就可以解决问题。
在我的工作中利用了一下几种方式达到这一目的：

* 全局均值

  我使用全局均值往往用来制造一个并不存在的人，这个人的行为数据是全局的均值
* User纬度均值

    对于某一个User可以使用他的行为数据均值作为缺失值，这样并不影响该User整体的行为数据
* Item纬度均值

    用物品的均值，作为该用户对该物品的行为数据，这种方式计算时往往代价较高
 
Mahout的作者在书中指出，虽然填充缺失值这种策略可行，但是在实际中往往没有帮助，还提高了计算的复杂度。所以通常用于实验研究而不是真实的数据。但按我的经验来看，在基于行为的推荐中，确实是不需要的，但是在基于模型的算法中例如矩阵分解，有时需要一个虚拟的人来占满矩阵中的一行，然后再进行计算，这时就可以利用全局均值来解决这个问题。
##9 Summary
当然还有一些其他的方式来计算相似性，但我只打算简单介绍以上这几种有代表性的方法。简单的归纳：
1. Pearson强调的数据移动的趋势，余弦相似度强调的是向量的夹角，欧式距离则体现在维度的多少计算实际距离。Jaccard和log-likelihood不要求具体的数值，只考虑共同记录占整体记录的比重，log-likelihood计算更加复杂，它对Jaccard表现更好。
2. Pearson对是否有共同记录敏感，如果没有共同行为记录，无法计算Pearson系数，所以在小数据集和稀疏数据集，Pearson的表现应该是最差的。
##10 a new novel approach
既然现有的方式都存在shortcomings，那有没有一种更为合适的方式呢？
简单的讲，现有的相似度量方式都存在一个问题，就是没有**充分考虑**评分向量的维度这一因子。
譬如，欧式距离只计算共同评分的记录，user 1与user 2共同评分项为15个，user 1与user 3共同评分项为100，那么在计算的时候很有可能1与2更相似，因为15维往往会比100维彼此更有可能接近，但是直觉上看1与3更相似。

在构思一个新的相似度量标准时，最好既考虑到每一项的评分，又考虑共同评分项的占比，这样就结合了Jaccrd和欧式的优点，又避免了Pearson和cosine只考虑趋势和夹角的问题。好消息是，已经有人这么做过了，参考paper---JacUOD:A New Similarity Measurement for Collaborative Filtering.

作者将Jaccard系数和变形后的欧式距离结合在了一起，对不同维度的向量空间进行了归一化，并在MovieLens的数据集上进行了测试，效果很好，但是只给出MAE的结果。今后打算在工程中实际应用下。
